import json
import os
import re  # <--- æ–°å¢ï¼šå¼•å…¥æ­£åˆ™æ¨¡å—ç”¨äºæ¸…æ´—æ•°æ®
import sys
from typing import Dict, List

from dotenv import load_dotenv
from langchain_community.document_loaders import TextLoader
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_milvus import Milvus
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()

# --- æ ¸å¿ƒé…ç½® ---
RAW_DOCS_DIR = "./data/raw_docs"
COLLECTION_NAME = "metro_knowledge" 
LOG_FILE = "./data/indexed_files.json"
LOCAL_MODEL_PATH = "./models/bge-small-zh-v1.5" 

# Milvus é…ç½® (ä½¿ç”¨ TCP åè®®)
MILVUS_HOST = "127.0.0.1"
MILVUS_PORT = 29530 

# ==========================================
# ğŸ› ï¸ å·¥ç¨‹å¸ˆä¼˜åŒ–ç‚¹ 1: æ•°æ®æ¸…æ´—å‡½æ•°
# ==========================================
def clean_text_content(text: str) -> str:
    """
    æ¸…æ´—åŸå§‹æ–‡æœ¬ï¼Œå»é™¤å¹²æ‰° RAG çš„å™ªéŸ³ã€‚
    """
    # 1. å»é™¤é¡µç  (ä¾‹å¦‚ "- 1 -", "Page 1")
    text = re.sub(r'-\s*\d+\s*-', '', text)
    
    # 2. å»é™¤å¤šä½™çš„è¿ç»­æ¢è¡Œ (è¶…è¿‡2ä¸ªæ¢è¡Œå˜æˆ2ä¸ªï¼Œä¿æŒæ®µè½æ„Ÿä½†å»é™¤å¤§ç‰‡ç©ºç™½)
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    # 3. å»é™¤ä¸å¯è§å­—ç¬¦ (å¦‚ \u200b ç­‰é›¶å®½å­—ç¬¦)
    text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', text)
    
    return text.strip()

def load_processed_log() -> Dict[str, float]:
    if os.path.exists(LOG_FILE):
        try:
            with open(LOG_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}

def save_processed_log(log_data: Dict[str, float]):
    with open(LOG_FILE, "w", encoding="utf-8") as f:
        json.dump(log_data, f, ensure_ascii=False, indent=2)

def get_all_files(directory: str, ext: str = ".txt") -> List[str]:
    file_paths = []
    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith(ext):
                file_paths.append(os.path.join(root, file))
    return file_paths

def build_index():
    # ==========================================
    # 0. ç¯å¢ƒæ¸…ç†
    # ==========================================
    print(">>> [Phase 0] æ¸…ç†ç½‘ç»œä»£ç†é…ç½®...")
    for key in ["http_proxy", "https_proxy", "all_proxy", "HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY", "grpc_proxy", "GRPC_PROXY"]:
        if key in os.environ:
            del os.environ[key]
    os.environ["NO_PROXY"] = "localhost,127.0.0.1,0.0.0.0,::1"

    # ==========================================
    # 1. åŠ è½½æœ¬åœ°æ¨¡å‹
    # ==========================================
    print(f">>> [Phase 1] æ­£åœ¨ä»æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹: {LOCAL_MODEL_PATH}")
    if not os.path.exists(LOCAL_MODEL_PATH):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶å¤¹ {LOCAL_MODEL_PATH}")
        return

    try:
        embeddings = HuggingFaceEmbeddings(
            model_name=LOCAL_MODEL_PATH,
            model_kwargs={'device': 'cpu'}, 
            encode_kwargs={'normalize_embeddings': True}
        )
        print(">>> âœ… æœ¬åœ°æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f">>> âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    # ==========================================
    # 2. å¤„ç†æ–‡ä»¶ (æ¸…æ´— + åŠ è½½)
    # ==========================================
    processed_log = load_processed_log()
    current_files = get_all_files(RAW_DOCS_DIR)
    
    # âš ï¸ åªè¦æœ‰æ–‡ä»¶ï¼Œæˆ‘ä»¬å°±é‡æ–°æ„å»ºï¼ˆä¸ºäº†åº”ç”¨æ–°çš„åˆ‡ç‰‡ç­–ç•¥ï¼Œä¸å†è·³è¿‡æ—§æ–‡ä»¶ï¼‰
    # å¦‚æœä½ æ–‡ä»¶ç‰¹åˆ«å¤šï¼Œå¯ä»¥æ¢å¤å¢é‡é€»è¾‘ï¼Œä½†ç°åœ¨ä¸ºäº†è°ƒè¯•ç²¾åº¦ï¼Œå»ºè®®æ¯æ¬¡å…¨é‡é‡è·‘
    new_files = current_files 
    updated_log = processed_log.copy()

    if not new_files:
        print(">>> ç›®å½•ä¸­æ²¡æœ‰æ–‡ä»¶ã€‚")
        return

    print(f">>> å‡†å¤‡å¤„ç† {len(new_files)} ä¸ªæ–‡ä»¶...")
    
    docs = []
    for file_path in new_files:
        try:
            loader = TextLoader(file_path, encoding="utf-8")
            loaded_docs = loader.load()
            
            for doc in loaded_docs:
                # âš¡ åº”ç”¨ä¼˜åŒ– 1: æ¸…æ´—æ–‡æœ¬
                doc.page_content = clean_text_content(doc.page_content)
                
                # âš¡ åº”ç”¨ä¼˜åŒ– 2: æ³¨å…¥æ›´æ¸…æ™°çš„å…ƒæ•°æ®
                doc.metadata["source_filename"] = os.path.basename(file_path)
                
                # (å¯é€‰) ä½ å¯ä»¥åœ¨è¿™é‡Œå°è¯•æå– "ç« èŠ‚æ ‡é¢˜" å¹¶åŠ å…¥ metadataï¼Œä½†è¿™éœ€è¦å¤æ‚çš„è§„åˆ™
            
            docs.extend(loaded_docs)
        except Exception as e:
            print(f"    x è¯»å–å¤±è´¥: {file_path}, {e}")

    if not docs:
        return

    # ==========================================
    # ğŸ› ï¸ å·¥ç¨‹å¸ˆä¼˜åŒ–ç‚¹ 2: ä¼˜åŒ–çš„åˆ‡ç‰‡ç­–ç•¥
    # ==========================================
    print(">>> æ­£åœ¨åˆ‡åˆ†æ–‡æ¡£ (ä½¿ç”¨ä¼˜åŒ–åçš„ç­–ç•¥)...")
    text_splitter = RecursiveCharacterTextSplitter(
        # 1. ç¼©å°å°ºå¯¸ï¼š350å­—ç¬¦é€šå¸¸åŒ…å«1-2ä¸ªå®Œæ•´æ¡æ¬¾ï¼Œé¿å…åŒ…å«è¿‡å¤šæ— å…³å™ªéŸ³
        chunk_size=350,
        # 2. é€‚åº¦é‡å ï¼šä¿è¯â€œæ¡æ¬¾å‰æâ€å’Œâ€œå…·ä½“å†…å®¹â€ä¸ä¼šå› ä¸ºåˆ‡åˆ†è€Œæ–­å¼€
        chunk_overlap=50,
        # 3. å¢å¼ºåˆ†éš”ç¬¦ï¼šåŠ å…¥ä¸­æ–‡è¯­ä¹‰ç¬¦å·ï¼Œä¼˜å…ˆçº§ä»å·¦åˆ°å³
        separators=[
            "\n\n", # ä¼˜å…ˆæŒ‰æ®µè½åˆ‡
            "\n",   # å…¶æ¬¡æŒ‰è¡Œåˆ‡
            "ã€‚",   # æŒ‰å¥å·åˆ‡
            "ï¼›",   # æŒ‰åˆ†å·åˆ‡ (æ³•å¾‹æ¡æ–‡å¸¸ç”¨)
            "ï¼", "ï¼Ÿ", " ", ""
        ]
    )
    splits = text_splitter.split_documents(docs)
    print(f">>> åˆ‡åˆ†å®Œæˆï¼Œå…± {len(splits)} ä¸ªé«˜å¯†åº¦åˆ‡ç‰‡ã€‚")

    # ==========================================
    # 3. é‡å»º Milvus é›†åˆ
    # ==========================================
    milvus_uri = f"tcp://{MILVUS_HOST}:{MILVUS_PORT}"
    print(f">>> æ­£åœ¨è¿æ¥ Milvus: {milvus_uri} å¹¶é‡å»ºé›†åˆ...")

    try:
        Milvus.from_documents(
            splits,
            embeddings,
            collection_name=COLLECTION_NAME,
            connection_args={
                "uri": milvus_uri, 
                "token": "",
                "timeout": 30
            },
            # âš ï¸ å¼ºåˆ¶æ¸…ç©ºæ—§æ•°æ®ï¼Œå› ä¸ºåˆ‡ç‰‡ç­–ç•¥å˜äº†ï¼Œæ—§å‘é‡å¿…é¡»ä½œåºŸ
            drop_old=True 
        )
        
        # æ›´æ–°æ—¥å¿—
        for file_path in new_files:
            file_name = os.path.relpath(file_path, RAW_DOCS_DIR)
            updated_log[file_name] = os.path.getmtime(file_path)
        save_processed_log(updated_log)
        
        print(f">>> ğŸ‰ æˆåŠŸï¼çŸ¥è¯†åº“å·²æŒ‰ç…§æ–°ç­–ç•¥é‡å»ºå®Œæˆ: {COLLECTION_NAME}")
        
    except Exception as e:
        print(f"\n>>> [é”™è¯¯] æ¨é€å¤±è´¥: {e}")
        if "connect" in str(e).lower():
            print("\nå»ºè®®æ’æŸ¥æ­¥éª¤:")
            print(f"1. ç»ˆç«¯æ‰§è¡Œ: nc -zv {MILVUS_HOST} {MILVUS_PORT}")

if __name__ == "__main__":
    build_index()