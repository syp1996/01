'''
Author: Yunpeng Shi
Description: å·¥ä¸šçº§æ”¹é€  - FastAPI æœåŠ¡ç«¯ + Postgres æŒä¹…åŒ– (ç¨³å®šç‰ˆ - ä½¿ç”¨é»˜è®¤äºŒè¿›åˆ¶å­˜å‚¨)
'''
import asyncio
import json
import os
import time
from contextlib import asynccontextmanager
from typing import AsyncGenerator

# å¯¼å…¥ä½ çš„æ™ºèƒ½ä½“
from agents.complaint_agent import complaint_agent
from agents.general_chat import general_chat
from agents.judge_agent import judge_agent
from agents.manager_agent import manager_agent
from agents.responder_agent import responder_agent
from agents.supervisor import supervisor_node, workflow_router
from agents.ticket_agent import ticket_agent
from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from langchain_core.messages import HumanMessage
# --- LangGraph & Postgres æ ¸å¿ƒç»„ä»¶ ---
from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver
from langgraph.graph import END, START, StateGraph
from psycopg_pool import AsyncConnectionPool
from pydantic import BaseModel
from state import agentState
from utils import logger  # å¼•å…¥æˆ‘ä»¬åˆšæ‰é…ç½®çš„ logger

load_dotenv()

# --- é…ç½® ---
DB_URI = os.getenv("DB_URI", "postgresql://user:password@localhost:5432/metro_agent_db")

# --- 1. æ„å»ºå›¾ (ä¿æŒä¸å˜) ---
def build_graph():
    workflow = StateGraph(agentState)
    
    workflow.add_node("supervisor_node", supervisor_node)
    workflow.add_node("ticket_agent", ticket_agent)
    workflow.add_node("complaint_agent", complaint_agent)
    workflow.add_node("general_chat", general_chat)
    workflow.add_node("manager_agent", manager_agent)
    workflow.add_node("judge_agent", judge_agent)
    workflow.add_node("responder_agent", responder_agent)

    workflow.add_edge(START, 'supervisor_node')
    workflow.add_conditional_edges(
        "supervisor_node",
        workflow_router,
        [
            "ticket_agent", "complaint_agent", "general_chat", 
            "manager_agent", "judge_agent", "responder_agent"
        ]
    )
    workflow.add_edge("ticket_agent", "supervisor_node")
    workflow.add_edge("complaint_agent", "supervisor_node")
    workflow.add_edge("general_chat", "supervisor_node")
    workflow.add_edge("manager_agent", "supervisor_node")
    workflow.add_edge("judge_agent", "supervisor_node")
    workflow.add_edge("responder_agent", END)
    
    return workflow

# --- 2. ç”Ÿå‘½å‘¨æœŸç®¡ç† ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    print(">>> æ­£åœ¨åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± ...")
    
    # kwargs={"autocommit": True} æ˜¯å¿…é¡»çš„ï¼Œç¡®ä¿äº‹åŠ¡è‡ªåŠ¨æäº¤
    async with AsyncConnectionPool(conninfo=DB_URI, max_size=20, kwargs={"autocommit": True}) as pool:
        app.state.pool = pool
        
        print(">>> æ­£åœ¨æ£€æŸ¥ Checkpoint è¡¨ç»“æ„ (ä½¿ç”¨é»˜è®¤äºŒè¿›åˆ¶å­˜å‚¨)...")
        async with pool.connection() as conn:
            # ã€å…³é”®ä¿®æ”¹ã€‘ä¸ä¼  serde å‚æ•° -> ä½¿ç”¨é»˜è®¤çš„ Msgpack (äºŒè¿›åˆ¶)
            # è¿™ä¼šè‡ªåŠ¨åˆ›å»ºæˆ–æ£€æŸ¥ checkpoints è¡¨ï¼ˆæ­¤æ—¶ checkpoint åˆ—ä¸º bytea ç±»å‹ï¼‰
            checkpointer = AsyncPostgresSaver(conn)
            await checkpointer.setup()
        
        print(">>> æ•°æ®åº“è¿æ¥æˆåŠŸï¼ŒæœåŠ¡å·²å°±ç»ªã€‚")
        yield
        
    print(">>> æ­£åœ¨å…³é—­æ•°æ®åº“è¿æ¥...")

# --- 3. åˆå§‹åŒ– FastAPI ---
app = FastAPI(title="Metro AI Agent Service", version="1.0.0", lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    query: str
    thread_id: str = "default_thread"

# --- 4. æ ¸å¿ƒ API æ¥å£ ---
@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    start_time = time.time()
    print(f"\nâš¡ [Debug Start] æ”¶åˆ°è¯·æ±‚: {request.thread_id}") 
    logger.info(f"æ”¶åˆ°æ–°è¯·æ±‚ | ThreadID: {request.thread_id}")

    async def event_generator() -> AsyncGenerator[str, None]:
        try:
            print(f"ğŸ‘‰ [1] æ­£åœ¨è·å–æ•°æ®åº“è¿æ¥...")
            async with app.state.pool.connection() as conn:
                print(f"âœ… [1] æ•°æ®åº“è¿æ¥è·å–æˆåŠŸï¼")
                
                checkpointer = AsyncPostgresSaver(conn)
                print(f"ğŸ‘‰ [2] æ­£åœ¨æ„å»ºå›¾...")
                workflow = build_graph()
                graph_app = workflow.compile(checkpointer=checkpointer)
                print(f"âœ… [2] å›¾æ„å»ºå®Œæˆ")
                
                config = {"configurable": {"thread_id": request.thread_id}}
                input_state = {"messages": [HumanMessage(content=request.query)]}
                
                # ã€ä¿®å¤ç‚¹ã€‘è¡¥ä¸Šäº†è¿™è¡Œåˆå§‹åŒ–ï¼
                started_nodes = set()
                
                print(f"ğŸ‘‰ [3] å‡†å¤‡å¼€å§‹æ‰§è¡Œ astream_events (è¿™æ­¥ä¼šè°ƒç”¨ LLM)...")
                
                has_event = False
                
                async for event in graph_app.astream_events(input_state, config=config, version="v1"):
                    has_event = True
                    kind = event["event"]
                    node_name = event.get("metadata", {}).get("langgraph_node", "æœªçŸ¥")
                    
                    # æ‰“å°äº‹ä»¶æµ
                    print(f"ğŸŒŠ [äº‹ä»¶æµ] æ”¶åˆ°äº‹ä»¶: {kind} (èŠ‚ç‚¹: {node_name})")
                    
                    if kind == "on_chain_start" and node_name and node_name not in ["__start__", "__end__", "supervisor_node"]:
                        if node_name not in started_nodes:
                            started_nodes.add(node_name)
                            yield f"event: agent_start\ndata: {json.dumps({'agent': node_name})}\n\n"

                    if kind == "on_chat_model_stream":
                        if node_name == "responder_agent":
                            chunk = event["data"]["chunk"]
                            if chunk.content:
                                yield f"event: message\ndata: {json.dumps({'content': chunk.content}, ensure_ascii=False)}\n\n"
                
                if not has_event:
                    print(f"âŒ [è­¦å‘Š] å¾ªç¯ç»“æŸäº†ï¼Œä½†æ²¡æœ‰æ”¶åˆ°ä»»ä½•äº‹ä»¶ï¼å¯èƒ½æ˜¯ LLM æ²¡ååº”ã€‚")
                else:
                    print(f"âœ… [ç»“æŸ] å›¾æ‰§è¡Œå®Œæ¯•")
                
                yield "event: done\ndata: [DONE]\n\n"
                
                duration = time.time() - start_time
                logger.info(f"è¯·æ±‚å¤„ç†æˆåŠŸ | è€—æ—¶: {duration:.2f}s")
                
        except Exception as e:
            print(f"âŒ [ä¸¥é‡æŠ¥é”™] æ•è·åˆ°å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            
            logger.error(f"è¯·æ±‚å¤„ç†å¤±è´¥", exc_info=True)
            yield f"event: error\ndata: {json.dumps({'error': str(e)})}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")

@app.get("/health")
def health_check():
    return {"status": "ok", "db": "connected"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)