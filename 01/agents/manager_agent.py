'''
Author: Yunpeng Shi y.shi27@newcastle.ac.uk
Date: 2026-02-05 12:08:44
LastEditors: Yunpeng Shi y.shi27@newcastle.ac.uk
LastEditTime: 2026-02-06 13:51:27
FilePath: /general_agent/01/agents/manager_agent.py
Description: è¿™æ˜¯é»˜è®¤è®¾ç½®,è¯·è®¾ç½®`customMade`, æ‰“å¼€koroFileHeaderæŸ¥çœ‹é…ç½® è¿›è¡Œè®¾ç½®: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE
'''
'''
Author: Yunpeng Shi
Description: ç®¡ç†æ™ºèƒ½ä½“ - å¼•å…¥ CoT ä¸å¤šå·¥å…·åè°ƒé€»è¾‘
'''
from typing import Annotated, List, TypedDict

from langchain_core.messages import (AIMessage, BaseMessage, HumanMessage,
                                     SystemMessage)
from langchain_core.tools import tool
from langgraph.graph import START, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from state import WorkerState
from utils import llm, update_task_result


# --- Tools å®šä¹‰ ---
@tool
def query_staff_roster(date: str, station: str = "æ‰€æœ‰ç«™ç‚¹") -> str:
    """æŸ¥è¯¢æŒ‡å®šæ—¥æœŸã€æŒ‡å®šç«™ç‚¹çš„å‘˜å·¥æ’ç­è¡¨ã€‚Args: date (YYYY-MM-DD), station"""
    return f"ã€{date} æ’ç­è¡¨ - {station}ã€‘\næ—©ç­: å¼ ä¸‰ (ç«™é•¿), æå›› (å®‰æ£€)\næ™šç­: ç‹äº” (å€¼ç­å‘˜)\nçŠ¶æ€: æ­£å¸¸"

@tool
def get_kpi_report(staff_name: str) -> str:
    """æŸ¥è¯¢æŒ‡å®šå‘˜å·¥çš„è¿‘æœŸç»©æ•ˆè€ƒæ ¸è¯„åˆ†ã€‚"""
    mock_data = {"å¼ ä¸‰": "A (ä¼˜ç§€)", "æå››": "B (è‰¯å¥½)", "ç‹äº”": "C (éœ€æ”¹è¿›)"}
    score = mock_data.get(staff_name, "æœªæ‰¾åˆ°è¯¥å‘˜å·¥è®°å½•")
    return f"å‘˜å·¥ {staff_name} çš„ä¸Šæœˆç»©æ•ˆè¯„çº§ä¸º: {score}"

tools = [query_staff_roster, get_kpi_report]
llm_with_tools = llm.bind_tools(tools)

# --- ReAct å¾®å‹å›¾ ---
class SubAgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]

def call_model(state: SubAgentState):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}

worker_workflow = StateGraph(SubAgentState)
worker_workflow.add_node("model", call_model)
worker_workflow.add_node("tools", ToolNode(tools))
worker_workflow.add_edge(START, "model")
worker_workflow.add_conditional_edges("model", tools_condition)
worker_workflow.add_edge("tools", "model")
react_app = worker_workflow.compile()

# --- ä¸» Agent é€»è¾‘ä¼˜åŒ– ---
async def manager_agent(state: WorkerState):
    task = state["task"]
    isolated_input = task['input_content']
    global_messages = state.get("messages", [])
    history_context = global_messages[:-1] if global_messages else []

    # ã€æ ¸å¿ƒä¼˜åŒ–ã€‘System Prompt å¼•å…¥ CoT
    system_prompt = """
    ä½ æ˜¯æ­å·åœ°é“çš„**å†…éƒ¨è¿è¥ç®¡ç†åŠ©æ‰‹**ã€‚æœåŠ¡å¯¹è±¡æ˜¯ç«™é•¿å’Œç®¡ç†å±‚ã€‚
    
    ### ğŸ§  æ·±åº¦æ€è€ƒæµç¨‹ (CoT):
    1. **ã€éœ€æ±‚æ‹†è§£ã€‘**ï¼šç”¨æˆ·æ˜¯æƒ³æŸ¥â€œäººâ€ï¼ˆç»©æ•ˆï¼‰è¿˜æ˜¯æŸ¥â€œäº‹â€ï¼ˆæ’ç­ï¼‰ï¼Ÿ
    2. **ã€å‚æ•°æ¸…æ´—ã€‘**ï¼š
       - æŸ¥æ’ç­ï¼šå¿…é¡»æ˜ç¡®æ—¥æœŸã€‚å¦‚æœç”¨æˆ·è¯´â€œä»Šå¤©â€ï¼Œè¯·è½¬æ¢ä¸ºå½“å‰æ—¥æœŸï¼ˆå‡è®¾ä¸º 2026-02-06ï¼‰ã€‚
       - æŸ¥ç»©æ•ˆï¼šå¿…é¡»æ˜ç¡®å§“åã€‚
    3. **ã€å·¥å…·è·¯ç”±ã€‘**ï¼š
       - æ’ç­ -> `query_staff_roster`
       - ç»©æ•ˆ -> `get_kpi_report`
    4. **ã€æ•°æ®æ•´åˆã€‘**ï¼šæ”¶åˆ°å·¥å…·è¿”å›åï¼Œæ•´ç†æˆç®€æ´çš„æ±‡æŠ¥æ ¼å¼ã€‚
    5. **å…³é”®æ ¼å¼è¦æ±‚ï¼š**
    æ€è€ƒå®Œæˆåï¼Œå¿…é¡»è¾“å‡º `=====FINAL_ANSWER=====`ï¼Œç„¶åç´§æ¥ç€è¾“å‡ºç¥¨ä»·æˆ–æ—¶é—´çš„å…·ä½“æ•°å­—/ä¿¡æ¯ã€‚

    ### ğŸ›¡ï¸ æ³¨æ„äº‹é¡¹ï¼š
    - æ¶‰åŠå†…éƒ¨æ•°æ®ï¼Œè¯­æ°”è¦ä¸¥è°¨ã€å®¢è§‚ã€‚
    - å¦‚æœç¼ºå°‘å…³é”®å‚æ•°ï¼ˆå¦‚æŸ¥æ’ç­æ²¡è¯´å“ªå¤©ï¼‰ï¼Œè¯·å…ˆæ€è€ƒé»˜è®¤å€¼æˆ–è¿½é—®ã€‚
    """
    
    inputs = {
        "messages": [
            SystemMessage(content=system_prompt),
            *history_context,
            HumanMessage(content=isolated_input)
        ]
    }
    
    result = await react_app.ainvoke(inputs)
    final_content = result["messages"][-1].content
    updated_task = update_task_result(task, result=final_content)
    
    input_len = len(inputs["messages"])
    generated_messages = result["messages"][input_len:]

    return {
        "task_board": [updated_task],
        "messages": generated_messages
    }