'''
Author: Yunpeng Shi
Description: ä¼˜åŒ–ç‰ˆ General Chat - å¼•å…¥æ€ç»´é“¾ (CoT) + ç»“æœæ‹¦æˆªé€»è¾‘
'''
import os
from typing import Annotated, List, TypedDict

import utils  # âœ… å¯¼å…¥æ•´ä¸ª utils
from langchain_core.messages import (AIMessage, BaseMessage, HumanMessage,
                                     SystemMessage)
from langchain_core.tools import tool
from langgraph.graph import START, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from state import WorkerState


@tool
async def search_knowledge(query: str) -> str:
    """
    å½“ç”¨æˆ·çš„é—®é¢˜æ¶‰åŠå…·ä½“çš„ã€ä¸“ä¸šçš„ã€æˆ–è€…å¯èƒ½å­˜åœ¨äºç§æœ‰/ç‰¹å®šçŸ¥è¯†åº“ä¸­çš„äº‹å®æ€§ä¿¡æ¯æ—¶ï¼Œè°ƒç”¨æ­¤å·¥å…·ã€‚
    ä¾‹å¦‚ï¼šå…·ä½“çš„åŠäº‹æµç¨‹ã€æŠ€æœ¯æ–‡æ¡£ã€ä¹¦ç±å†…å®¹ã€æ·±åº¦ç™¾ç§‘çŸ¥è¯†ç­‰ã€‚
    """
    
    # âœ… åŠ¨æ€è·å–ï¼Œæ”¯æŒ Mock
    store = utils.get_vector_store()
    
    if not store:
        return "ç³»ç»Ÿæç¤ºï¼šçŸ¥è¯†åº“æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç›´æ¥æ ¹æ®å¸¸è¯†å›ç­”ã€‚"

    try:
        retriever = store.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={"k": 3, "score_threshold": 0.4}
        )
        docs = await retriever.ainvoke(query)
        
        if not docs:
            return "ã€æ£€ç´¢ç»“æœã€‘çŸ¥è¯†åº“ä¸­æœªåŒ…å«ç›¸å…³å…·ä½“è§„å®šã€‚è¯·ä½ åŸºäºé€šç”¨çŸ¥è¯†å›ç­”ç”¨æˆ·ï¼Œä¸è¦å†æ¬¡å°è¯•æ£€ç´¢ã€‚"
        
        results = []
        for i, doc in enumerate(docs):
            clean_content = doc.page_content.replace('\n', ' ')
            results.append(f"ã€æ¡æ¬¾ {i+1}ã€‘: {clean_content}")
            
        return "\n\n".join(results)
    except Exception as e:
        return f"ç³»ç»Ÿé”™è¯¯ï¼šçŸ¥è¯†åº“æ£€ç´¢å¤±è´¥ ({str(e)})ã€‚"

tools = [search_knowledge]
llm_with_tools = utils.llm.bind_tools(tools)

class SubAgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]

def call_model(state: SubAgentState):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}

worker_workflow = StateGraph(SubAgentState)
worker_workflow.add_node("model", call_model)
worker_workflow.add_node("tools", ToolNode(tools))
worker_workflow.add_edge(START, "model")
worker_workflow.add_conditional_edges("model", tools_condition)
worker_workflow.add_edge("tools", "model")
react_app = worker_workflow.compile()

async def general_chat(state: WorkerState):
    task = state["task"]
    isolated_input = task['input_content']
    global_messages = state.get("messages", [])
    
    # --- æ ¸å¿ƒä¿®æ”¹ï¼šå‡çº§ç‰ˆ System Prompt (é€‚é…å‰ç«¯ Title/Content æ ¼å¼å±•ç¤º) ---
    system_prompt = """
    ä½ æ˜¯**å…¨èƒ½çŸ¥è¯†åŠ©æ‰‹ (Omni-Assistant)**ï¼Œè´Ÿè´£ä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€é€»è¾‘æ¸…æ™°ä¸”å‹å¥½çš„å›ç­”ã€‚
    
    ### ğŸ§  ä½ çš„æ€è€ƒæ¨¡å¼ (Structured Thinking)
    åœ¨è¾“å‡ºæœ€ç»ˆå›å¤ä¹‹å‰ï¼Œä½ å¿…é¡»å±•ç¤ºä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚
    **ä¸ºäº†è®©ç³»ç»Ÿèƒ½å¤Ÿæ­£ç¡®å±•ç¤ºä½ çš„æ€è€ƒæ­¥éª¤ï¼Œè¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š**
    
    Title: <æ­¥éª¤æ ‡é¢˜ï¼Œä¾‹å¦‚ï¼šæ„å›¾åˆ†ç±» / æ£€ç´¢å¿…è¦æ€§è¯„ä¼° / ç­”æ¡ˆæ•´åˆç­–ç•¥>
    Content: <è¯¦ç»†çš„æ€è€ƒå†…å®¹ï¼Œæè¿°ä½ å¦‚ä½•ç†è§£é—®é¢˜ï¼Œä»¥åŠä½ æ˜¯å¦éœ€è¦ä¾èµ–å¤–éƒ¨çŸ¥è¯†åº“ã€‚>
    
    **è¾“å‡ºç¤ºä¾‹ (é€šç”¨é—®ç­”)ï¼š**
    Title: æ„å›¾åˆ†æ
    Content: ç”¨æˆ·è¯¢é—®çš„æ˜¯é‡å­åŠ›å­¦çš„åŸºæœ¬æ¦‚å¿µã€‚è¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„ç§‘å­¦å¸¸è¯†é—®é¢˜ï¼Œæˆ‘ç›´æ¥ç”¨å†…éƒ¨é¢„è®­ç»ƒçŸ¥è¯†å³å¯è§£é‡Šæ¸…æ¥šï¼Œæ— éœ€è°ƒç”¨çŸ¥è¯†åº“ã€‚
    
    **è¾“å‡ºç¤ºä¾‹ (çŸ¥è¯†åº“é—®ç­”)ï¼š**
    Title: æ£€ç´¢å¿…è¦æ€§è¯„ä¼°
    Content: ç”¨æˆ·è¯¢é—®çš„æ˜¯â€œæœ€æ–°å¹´åº¦ä¼šå‘˜æƒç›Šè¯´æ˜â€ã€‚è¿™æ¶‰åŠåˆ°ç‰¹å®šä¸”å¯èƒ½éšæ—¶é—´å˜åŒ–çš„è§„ç« å†…å®¹ï¼Œä¸ºäº†ä¿è¯å‡†ç¡®æ€§ï¼Œæˆ‘å¿…é¡»è°ƒç”¨ `search_knowledge` å·¥å…·ã€‚

    ### ğŸ›¡ï¸ è¿è¡Œå‡†åˆ™ï¼š
    1. **ä¼˜å…ˆæ£€ç´¢åŸåˆ™**ï¼š
       - å‡¡æ˜¯æ¶‰åŠ**ç‰¹å®šæµç¨‹ã€ä¸“æœ‰åè¯ã€ç§æœ‰æ–‡æ¡£ã€æ•°æ®å¯¹æ¯”ã€æ³•å¾‹æ³•è§„**ç­‰é—®é¢˜ï¼Œ**å¿…é¡»**å…ˆè°ƒç”¨ `search_knowledge`ã€‚
       - å³ä½¿ä½ è®¤ä¸ºè‡ªå·±çŸ¥é“ç­”æ¡ˆï¼Œä¹Ÿè¦é€šè¿‡æ£€ç´¢æ¥æ ¸å®ï¼Œé˜²æ­¢å‡ºç°å¹»è§‰ã€‚
       
    2. **å¸¸è¯†ç›´æ¥å›ç­”**ï¼š
       - é—²èŠï¼ˆä½ å¥½ã€ä½ æ˜¯è°ï¼‰ã€é€šè¯†æ€§ç§‘æ™®ï¼ˆä¸ºä»€ä¹ˆä¸‹é›¨ï¼‰ã€ç®€å•çš„è¯­è¨€ç¿»è¯‘ã€ä»£ç ç”Ÿæˆã€åˆ›æ„å†™ä½œç­‰ï¼Œ**ä¸¥ç¦**è°ƒç”¨å·¥å…·ã€‚
       
    3. **å¼•ç”¨æ ‡æ³¨**ï¼š
       - å¦‚æœä½¿ç”¨äº† `search_knowledge` çš„ç»“æœï¼Œè¯·åœ¨å›å¤ä¸­å°½é‡ä½“ç°â€œæ ¹æ®ç›¸å…³èµ„æ–™æ˜¾ç¤º...â€ã€‚
       
    4. **æ€åº¦**ï¼š
       - ä¿æŒå®¢è§‚ã€ä¸“ä¸šä¸”æœ‰æ¸©åº¦ã€‚å¦‚æœçŸ¥è¯†åº“æ²¡æŸ¥åˆ°ï¼Œè¯·ç›´è¯´â€œåœ¨ç°æœ‰èµ„æ–™ä¸­æœªæ‰¾åˆ°â€ï¼Œç„¶åç»™å‡ºä½ çš„åˆç†å»ºè®®ã€‚
    """
    
    # æ„é€ è¾“å…¥
    inputs = {
        "messages": [
            SystemMessage(content=system_prompt),
            *global_messages[:-1],
            HumanMessage(content=isolated_input)
        ]
    }
    
    # æ‰§è¡Œå›¾
    result = await react_app.ainvoke(inputs)
    final_content = result["messages"][-1].content
    
    # æ›´æ–°ä»»åŠ¡ç»“æœ
    updated_task = utils.update_task_result(task, result=final_content)
    
    # è®¡ç®—å¢é‡æ¶ˆæ¯
    input_len = len(inputs["messages"])
    generated_messages = result["messages"][input_len:]

    return {
        "task_board": [updated_task],
        "messages": generated_messages
    }