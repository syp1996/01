'''
Author: Yunpeng Shi y.shi27@newcastle.ac.uk
FilePath: /01/agents/general_chat.py
Description: å¹¶è¡ŒåŒ–æ”¹é€ ç‰ˆ - ä¿®å¤ TypedDict è°ƒç”¨è¡¨è¾¾å¼æŠ¥é”™ (æœ€ç»ˆç¨³å®šç‰ˆ)
'''
import os
from typing import Annotated, List, TypedDict

from langchain_core.messages import (AIMessage, BaseMessage, HumanMessage,
                                     SystemMessage)
from langchain_core.tools import tool
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_milvus import Milvus
from langgraph.graph import START, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
# agents/general_chat.py é¡¶éƒ¨
from utils import complete_current_task  # âš ï¸ ç¡®ä¿åŠ ä¸Š get_vector_store
from utils import get_vector_store, llm, update_task_result

from state import WorkerState

# --- å…¨å±€å˜é‡å…ˆè®¾ä¸º None ---
vector_store = None
embeddings = None

def get_vector_store():
    """æ‡’åŠ è½½å‡½æ•°ï¼šåªæœ‰åœ¨çœŸæ­£éœ€è¦çš„æ—¶å€™æ‰åˆå§‹åŒ–è¿æ¥"""
    global vector_store, embeddings
    
    # å¦‚æœå·²ç»åˆå§‹åŒ–è¿‡ï¼Œç›´æ¥è¿”å›
    if vector_store is not None:
        return vector_store

    print(f">>> [General Chat] æ­£åœ¨åˆå§‹åŒ– Milvus è¿æ¥... (å»¶è¿ŸåŠ è½½)")
    
    # è¿™é‡Œå®šä¹‰é…ç½®
    MILVUS_URI = "tcp://127.0.0.1:29530" 
    COLLECTION_NAME = "metro_knowledge"
    LOCAL_MODEL_PATH = "./models/bge-small-zh-v1.5"

    try:
        embeddings = HuggingFaceEmbeddings(
            model_name=LOCAL_MODEL_PATH,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )

        vector_store = Milvus(
            embedding_function=embeddings,
            collection_name=COLLECTION_NAME,
            connection_args={
                "uri": MILVUS_URI,
                "token": "",
                "timeout": 30
            },
            index_params={"metric_type": "L2", "index_type": "HNSW", "params": {"M": 8, "efConstruction": 64}},
            auto_id=True
        )
        print(">>> [General Chat] RAG ç»„ä»¶åŠ è½½æˆåŠŸï¼")
        return vector_store
        
    except Exception as e:
        print(f">>> âŒ [General Chat] åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

@tool
async def lookup_policy(query: str) -> str:
    """æŸ¥è¯¢åœ°é“ç›¸å…³è§„ç« åˆ¶åº¦ã€ä¹˜è½¦å®ˆåˆ™ç­‰å®˜æ–¹æ–‡æ¡£ã€‚"""
    
    # åœ¨ä¸»äº‹ä»¶å¾ªç¯ä¸­è·å– storeï¼Œè¿™ä¸‹æœ‰ Loop äº†
    store = get_vector_store()
    
    if not store:
        return "ç³»ç»Ÿé”™è¯¯ï¼šçŸ¥è¯†åº“æœªæ­£ç¡®åˆå§‹åŒ–ï¼ˆè¯·æ£€æŸ¥ Milvus æœåŠ¡æˆ–æ§åˆ¶å°æŠ¥é”™æ—¥å¿—ï¼‰ã€‚"

    try:
        retriever = store.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={
                "k": 5, 
                "score_threshold": 0.4,
                "param": {"metric_type": "L2", "nprobe": 10} 
            }
        )
        
        # 2. æ£€ç´¢ä¹Ÿå»ºè®®æ”¹ä¸ºå¼‚æ­¥è°ƒç”¨ (await .ainvoke)
        docs = await retriever.ainvoke(query)
        
        if not docs:
            return "æœªåœ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³è§„å®šã€‚"
        
        results = []
        for i, doc in enumerate(docs):
            source = doc.metadata.get('source_filename', 'æœªçŸ¥')
            clean_content = doc.page_content.replace('\n', ' ')
            results.append(f"ã€æ¡æ¬¾ {i+1}ã€‘(æ¥æº: {source}): {clean_content}")
            
        return "\n\n".join(results)
    except Exception as e:
        return f"ç³»ç»Ÿé”™è¯¯ï¼šçŸ¥è¯†åº“æ£€ç´¢å¤±è´¥ ({str(e)})ã€‚"
# --- 2. ReAct å­å›¾å®šä¹‰ (ä¿®å¤æŠ¥é”™çš„å…³é”®éƒ¨åˆ†) ---

tools = [lookup_policy]
llm_with_tools = llm.bind_tools(tools)

# ã€ä¿®å¤ã€‘æ˜¾å¼å®šä¹‰ TypedDict ç±»ï¼Œè€Œä¸æ˜¯åœ¨å‡½æ•°å‚æ•°é‡Œè°ƒç”¨æ„é€ å‡½æ•°
class SubAgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]

def call_model(state: SubAgentState):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}

# ã€ä¿®å¤ã€‘ä½¿ç”¨å®šä¹‰å¥½çš„ç±»
rag_workflow = StateGraph(SubAgentState)
rag_workflow.add_node("agent", call_model)
rag_workflow.add_node("tools", ToolNode(tools))
rag_workflow.add_edge(START, "agent")
rag_workflow.add_conditional_edges("agent", tools_condition)
rag_workflow.add_edge("tools", "agent")
rag_app = rag_workflow.compile()

# --- 3. ä¸»å‡½æ•° ---

async def general_chat(state: WorkerState):
    task = state["task"]
    isolated_input = task['input_content']

    # ã€æ ¸å¿ƒé€»è¾‘ã€‘è·å–å¹¶å¤„ç†å†å²
    global_messages = state.get("messages", [])
    print(f"[General] æ­£åœ¨å¤„ç† (RAGå·²å¯ç”¨): {isolated_input}")

    # æŠ€å·§ï¼šå…¨å±€å†å²çš„æœ€åä¸€æ¡é€šå¸¸æ˜¯ç”¨æˆ·æœ¬è½®çš„â€œå¤æ‚æŒ‡ä»¤â€ï¼ˆè¢« Supervisor æ‹†è§£å‰çš„ï¼‰ã€‚
    # ä¸ºäº†è®© Worker ä¸“æ³¨å¤„ç† isolated_inputï¼Œæˆ‘ä»¬é€šå¸¸å–â€œä¸Šä¸€è½®ä¸ºæ­¢çš„å†å²â€ä½œä¸º Contextã€‚
    history_context = global_messages[:-1] if global_messages else []

    # å¼ºåŒ– Prompt (Few-Shot)
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªäº²åˆ‡ã€ä¸“ä¸šçš„åœ°é“ç»¼åˆæœåŠ¡åŠ©æ‰‹ã€‚
    ä½ çš„ä¸»è¦èŒè´£æ˜¯é™ªä¹˜å®¢é—²èŠï¼Œæˆ–è€…ä¾æ®çœŸå®è§„å®šè§£ç­”åœ°é“æ”¿ç­–é—®é¢˜ã€‚

    ### æ ¸å¿ƒæŒ‡ä»¤ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š
    1. **å¿…é¡»æŸ¥è¯**ï¼šå½“ç”¨æˆ·é—®åˆ°å…·ä½“çš„è§„å®šã€æ”¿ç­–ï¼ˆå¦‚æºå¸¦ç‰©å“ã€å®‰æ£€ã€ç¥¨åŠ¡è§„åˆ™ï¼‰æ—¶ï¼Œ**å¿…é¡»è°ƒç”¨ lookup_policy å·¥å…·**ã€‚
    2. **å¼ºåˆ¶æ ‡è®°**ï¼šå‡¡æ˜¯ä½ çš„å›ç­”ä¸­å¼•ç”¨äº† `lookup_policy` å·¥å…·è¿”å›çš„ä¿¡æ¯ï¼Œ**å¿…é¡»**åœ¨å¯¹åº”çš„å¥å­æœ«å°¾åŠ ä¸Š `ã€ğŸ“šçŸ¥è¯†åº“ã€‘` æ ‡è®°ã€‚è¿™æ˜¯ä¸ºäº†å‘ç”¨æˆ·è¯æ˜ä¿¡æ¯çš„æƒå¨æ€§ã€‚
    
    ### ç¤ºä¾‹å­¦ä¹ ï¼ˆè¯·æ¨¡ä»¿ï¼‰ï¼š
    - ç”¨æˆ·ï¼šèƒ½å¸¦ç™½é…’è¿›ç«™å—ï¼Ÿ
    - å·¥å…·è¿”å›ï¼š...50åº¦ä»¥ä¸Šæ•£è£…ç™½é…’ç¦æ­¢æºå¸¦...
    - âŒ é”™è¯¯å›ç­”ï¼šæ ¹æ®è§„å®šï¼Œæ•£è£…çš„é«˜æµ“åº¦ç™½é…’æ˜¯ä¸è®©å¸¦çš„ã€‚
    - âœ… æ­£ç¡®å›ç­”ï¼šä¸ºæ‚¨æŸ¥è¯¢äº†ç›¸å…³è§„å®šï¼Œ50åº¦ä»¥ä¸Šçš„æ•£è£…ç™½é…’æ˜¯ç¦æ­¢æºå¸¦è¿›ç«™çš„ã€ğŸ“šçŸ¥è¯†åº“ã€‘ã€‚

    3. **è¯šå®åŸåˆ™**ï¼šå¦‚æœå·¥å…·æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œè¯·ç›´æ¥å‘Šè¯‰ç”¨æˆ·â€œæš‚æœªæŸ¥åˆ°ç›¸å…³è§„å®šâ€ï¼Œè¿™ç§æƒ…å†µä¸‹**ä¸éœ€è¦**åŠ æ ‡è®°ã€‚
    """

    # ã€æ„é€ è¾“å…¥ã€‘ System + å†å²Context + å½“å‰çº¯å‡€æŒ‡ä»¤
    inputs = {
        "messages": [SystemMessage(content=system_prompt)] + history_context + [HumanMessage(content=isolated_input)]
    }
    result = await rag_app.ainvoke(inputs)
    final_content = result["messages"][-1].content
    
    return {
        "messages": [AIMessage(content=final_content, name="general_chat")],
        "task_board": [update_task_result(task, result=final_content)]
    }