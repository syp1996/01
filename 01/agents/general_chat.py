'''
Author: Yunpeng Shi y.shi27@newcastle.ac.uk
FilePath: /01/agents/general_chat.py
Description: å¹¶è¡ŒåŒ–æ”¹é€ ç‰ˆ - ä¿®å¤ Mock æ‹¦æˆªé€»è¾‘
'''
import os
from typing import Annotated, List, TypedDict

# 1. å¯¼å…¥ utils æ¨¡å—
import utils
from langchain_core.messages import (AIMessage, BaseMessage, HumanMessage,
                                     SystemMessage)
from langchain_core.tools import tool
from langgraph.graph import START, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
# ä» utils å¯¼å…¥å¿…è¦çš„å‡½æ•°å’Œå¯¹è±¡
from utils import complete_current_task, llm, update_task_result

from state import WorkerState


@tool
async def lookup_policy(query: str) -> str:
    """æŸ¥è¯¢åœ°é“ç›¸å…³è§„ç« åˆ¶åº¦ã€ä¹˜è½¦å®ˆåˆ™ç­‰å®˜æ–¹æ–‡æ¡£ã€‚"""
    
    # âœ… æ ¸å¿ƒä¿®æ­£ï¼šæ˜¾å¼è°ƒç”¨ utils æ¨¡å—é‡Œçš„å‡½æ•°
    # è¿™æ ·æµ‹è¯•ä»£ç é‡Œçš„ @patch("utils.get_vector_store") æ‰èƒ½ 100% æ‹¦æˆªæˆåŠŸ
    store = utils.get_vector_store()
    
    if not store:
        return "ç³»ç»Ÿé”™è¯¯ï¼šçŸ¥è¯†åº“æœªæ­£ç¡®åˆå§‹åŒ–ã€‚"

    try:
        retriever = store.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={
                "k": 5, 
                "score_threshold": 0.4,
                "param": {"metric_type": "L2", "nprobe": 10} 
            }
        )
        
        docs = await retriever.ainvoke(query)
        
        if not docs:
            return "æœªåœ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³è§„å®šã€‚"
        
        results = []
        for i, doc in enumerate(docs):
            source = doc.metadata.get('source_filename', 'æœªçŸ¥')
            clean_content = doc.page_content.replace('\n', ' ')
            results.append(f"ã€æ¡æ¬¾ {i+1}ã€‘(æ¥æº: {source}): {clean_content}")
            
        return "\n\n".join(results)
    except Exception as e:
        return f"ç³»ç»Ÿé”™è¯¯ï¼šçŸ¥è¯†åº“æ£€ç´¢å¤±è´¥ ({str(e)})ã€‚"

# --- 2. ReAct å­å›¾å®šä¹‰ ---

tools = [lookup_policy]
llm_with_tools = llm.bind_tools(tools)

class SubAgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]

def call_model(state: SubAgentState):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}

rag_workflow = StateGraph(SubAgentState)
rag_workflow.add_node("agent", call_model)
rag_workflow.add_node("tools", ToolNode(tools))
rag_workflow.add_edge(START, "agent")
rag_workflow.add_conditional_edges("agent", tools_condition)
rag_workflow.add_edge("tools", "agent")
rag_app = rag_workflow.compile()

# --- 3. ä¸»å‡½æ•° ---

async def general_chat(state: WorkerState):
    task = state["task"]
    isolated_input = task['input_content']
    global_messages = state.get("messages", [])
    history_context = global_messages[:-1] if global_messages else []

    system_prompt = """ä½ æ˜¯ä¸€ä¸ªäº²åˆ‡ã€ä¸“ä¸šçš„åœ°é“ç»¼åˆæœåŠ¡åŠ©æ‰‹ã€‚
    ä½ çš„ä¸»è¦èŒè´£æ˜¯é™ªä¹˜å®¢é—²èŠï¼Œæˆ–è€…ä¾æ®çœŸå®è§„å®šè§£ç­”åœ°é“æ”¿ç­–é—®é¢˜ã€‚

    ### æ ¸å¿ƒæŒ‡ä»¤ï¼š
    1. **å¿…é¡»æŸ¥è¯**ï¼šæ¶‰åŠåœ°é“æ”¿ç­–é—®é¢˜å¿…é¡»è°ƒç”¨ lookup_policyã€‚
    2. **å¼ºåˆ¶æ ‡è®°**ï¼šå¼•ç”¨çŸ¥è¯†åº“ä¿¡æ¯å¿…é¡»åœ¨å¥æœ«åŠ  `ã€ğŸ“šçŸ¥è¯†åº“ã€‘`ã€‚
    """

    inputs = {
        "messages": [SystemMessage(content=system_prompt)] + history_context + [HumanMessage(content=isolated_input)]
    }
    result = await rag_app.ainvoke(inputs)
    final_content = result["messages"][-1].content
    
    return {
        "messages": [AIMessage(content=final_content, name="general_chat")],
        "task_board": [update_task_result(task, result=final_content)]
    }    